{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh-E3Go2UUbR"
      },
      "source": [
        "#  Title: Solving an Image Captioning Task Using Deep Learning\n",
        "\n",
        "**Major Project**\n",
        "\n",
        "**Team:- D**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBAad_nlVF8G"
      },
      "source": [
        "*Description*\n",
        "\n",
        "This project aims to generate descriptive captions for images using deep learning techniques, combining Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks (LSTM). The project will involve data preparation, feature extraction, model building, training, evaluation, and fine-tuning to achieve accurate and coherent image descriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnqfkLSDPVLU"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add, Attention\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iEORyzJY_Fq"
      },
      "source": [
        " ***Configuration***\n",
        "\n",
        "This section defines all core settings required for the image captioning project. It includes paths for images and annotations, dataset size selection, and key hyperparameters such as image resolution, vocabulary size, embedding dimensions, LSTM units, and learning rate. These configurations ensure that the entire pipeline remains flexible and easy to adjust based on available resources and training needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9051QkY95O72",
        "outputId": "561e9b09-64d9-4d70-8c5d-48cd1ad0093c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "IMAGE CAPTIONING PROJECT - STARTED\n",
            "================================================================================\n",
            "\n",
            " Dataset Configuration: MEDIUM\n",
            "   Images to process: 1000\n",
            "   Estimated time: ~20 min\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "IMAGE_DIR = \"/content/drive/MyDrive/Colab Notebooks/Major project/images/val2017\"  # Please update this to your actual image directory\n",
        "CAPTION_FILE = \"/content/drive/MyDrive/Colab Notebooks/Major project/Annotations/captions_val2017.json\"\n",
        "\n",
        "# Dataset size configuration\n",
        "# Options: 'small' (200 images), 'medium' (1000 images), 'large' (all 5000 images)\n",
        "DATASET_SIZE = 'medium'\n",
        "DATASET_SIZES = {\n",
        "    'small': 200,\n",
        "    'medium': 1000,\n",
        "    'large': None\n",
        "}\n",
        "\n",
        "NUM_IMAGES = DATASET_SIZES[DATASET_SIZE]\n",
        "\n",
        "\n",
        "IMG_SIZE = (299, 299)\n",
        "MAX_CAPTION_LENGTH = 20\n",
        "VOCAB_SIZE = 4000\n",
        "EMBEDDING_DIM = 256\n",
        "LSTM_UNITS = 512\n",
        "ATTENTION_DIM = 256\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"IMAGE CAPTIONING PROJECT - STARTED\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n Dataset Configuration: {DATASET_SIZE.upper()}\")\n",
        "print(f\"   Images to process: {NUM_IMAGES if NUM_IMAGES else 'All (~5000)'}\")\n",
        "print(f\"   Estimated time: {['~5 min', '~20 min', '~2 hours'][['small', 'medium', 'large'].index(DATASET_SIZE)]}\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxTCGqYgxeaO",
        "outputId": "6e68e542-4b75-47bd-c203-16928f0cb93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Zjtlr3VqeJ"
      },
      "source": [
        "***Step 1: Data Preparation***\n",
        "\n",
        "In this section, we prepare both the images and captions so they can be used for model training.\n",
        "We resize all images to 299×299, normalize pixel values, and process captions by removing punctuation, tokenizing them, and padding them to a fixed length.\n",
        "This ensures that all inputs follow the same format and can be fed into the neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckZSRXO_ayVZ",
        "outputId": "e963599f-75c9-4ee7-e175-360b108268ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[STEP 1] DATA PREPARATION\n",
            "--------------------------------------------------------------------------------\n",
            "Loading MS COCO captions...\n",
            " Total images: 5000\n",
            " Total captions: 25014\n",
            " Average captions per image: 5.00\n",
            "\n",
            "Sample preprocessed caption:\n",
            "  <start> a black honda motorcycle parked in front of a garage <end>\n",
            "\n",
            "Tokenizing captions...\n",
            " Vocabulary size: 4000\n",
            " Most common words: [('<unk>', 1), ('a', 2), ('<start>', 3), ('<end>', 4), ('on', 5), ('of', 6), ('the', 7), ('in', 8), ('with', 9), ('and', 10)]\n",
            " Max caption length: 20\n",
            " Tokenizer saved to 'tokenizer.pkl'\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 1: DATA PREPARATION\n",
        "# ============================================================================\n",
        "print(\"\\n[STEP 1] DATA PREPARATION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Load MS COCO captions\n",
        "print(\"Loading MS COCO captions...\")\n",
        "with open(CAPTION_FILE, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Create image_id -> captions mapping\n",
        "image_to_captions = defaultdict(list)\n",
        "for annotation in coco_data['annotations']:\n",
        "    image_id = annotation['image_id']\n",
        "    caption = annotation['caption']\n",
        "    image_to_captions[image_id].append(caption)\n",
        "\n",
        "# Create image_id -> filename mapping\n",
        "id_to_filename = {}\n",
        "for image in coco_data['images']:\n",
        "    id_to_filename[image['id']] = image['file_name']\n",
        "\n",
        "print(f\" Total images: {len(id_to_filename)}\")\n",
        "print(f\" Total captions: {sum(len(caps) for caps in image_to_captions.values())}\")\n",
        "print(f\" Average captions per image: {sum(len(caps) for caps in image_to_captions.values()) / len(id_to_filename):.2f}\")\n",
        "\n",
        "# Preprocessing captions\n",
        "def preprocess_caption(caption):\n",
        "\n",
        "    caption = caption.lower()\n",
        "    caption = ''.join([c for c in caption if c.isalnum() or c.isspace()])\n",
        "    caption = '<start> ' + ' '.join(caption.split()) + ' <end>'\n",
        "    return caption\n",
        "\n",
        "# Process all captions\n",
        "all_captions = []\n",
        "for captions in image_to_captions.values():\n",
        "    for caption in captions:\n",
        "        all_captions.append(preprocess_caption(caption))\n",
        "\n",
        "print(f\"\\nSample preprocessed caption:\")\n",
        "print(f\"  {all_captions[0]}\")\n",
        "\n",
        "# Tokenize captions\n",
        "print(\"\\nTokenizing captions...\")\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<unk>', filters='')\n",
        "tokenizer.fit_on_texts(all_captions)\n",
        "vocab_size = min(len(tokenizer.word_index) + 1, VOCAB_SIZE)\n",
        "\n",
        "print(f\" Vocabulary size: {vocab_size}\")\n",
        "print(f\" Most common words: {list(tokenizer.word_index.items())[:10]}\")\n",
        "\n",
        "# Calculate max caption length\n",
        "caption_lengths = [len(cap.split()) for cap in all_captions]\n",
        "max_length = min(max(caption_lengths), MAX_CAPTION_LENGTH)\n",
        "print(f\" Max caption length: {max_length}\")\n",
        "\n",
        "# Save tokenizer\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "print(\" Tokenizer saved to 'tokenizer.pkl'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWP5klC1WgI8"
      },
      "source": [
        "***Step 2 — Image Feature Extraction***\n",
        "\n",
        "In this step, we extract meaningful visual features from each image using a pre-trained InceptionV3 model. Before extraction, the notebook performs diagnostics to ensure all image paths and filenames match the JSON annotation file.\n",
        "Each image is then resized, normalized, and passed through InceptionV3 (with the classification layer removed) to generate a 2048-dimensional feature vector. These vectors capture high-level visual patterns—such as objects, textures, and shapes—which will later act as the encoder input for the captioning model.\n",
        "We also filter out missing files, restrict the dataset size when needed, and store extracted features in a dictionary for efficient training.\n",
        "\n",
        "If you want, I can also rewrite it in even more concise or more detailed form depending on your notebook style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EqlUzxtaymZ",
        "outputId": "85ebcf94-04af-4efb-8cfb-4154d324637e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[STEP 2] FEATURE EXTRACTION\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            " DIAGNOSTICS - Checking image paths...\n",
            "Image directory: /content/drive/MyDrive/Colab Notebooks/Major project/images/val2017\n",
            "Directory exists: True\n",
            "Total files in directory: 5000\n",
            "Image files found: 5000\n",
            "Sample filenames: ['000000052412.jpg', '000000218362.jpg', '000000493566.jpg']\n",
            "\n",
            "Sample expected filenames from JSON:\n",
            "  000000397133.jpg -  Found\n",
            "  000000037777.jpg -  Found\n",
            "  000000252219.jpg -  Found\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Loading InceptionV3 model (pre-trained on ImageNet)...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            " Model loaded. Output shape: (None, 2048)\n",
            "\n",
            "Extracting image features...\n",
            "Processing 1000 images...\n",
            "Actual images in folder: 5000\n",
            "Images matching JSON annotations: 5000\n",
            "Limited to: 1000 images for medium dataset\n",
            "\n",
            " Starting feature extraction (this may take a few minutes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 1000/1000 [04:24<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted features: 1000 images\n",
            " Features extracted for 1000 images\n",
            " Features saved to '/content/drive/MyDrive/image_features_medium.npy'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 2: FEATURE EXTRACTION\n",
        "# ============================================================================\n",
        "print(\"\\n[STEP 2] FEATURE EXTRACTION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# ===== DIAGNOSTICS: Check image directory =====\n",
        "print(\"\\n DIAGNOSTICS - Checking image paths...\")\n",
        "print(f\"Image directory: {IMAGE_DIR}\")\n",
        "print(f\"Directory exists: {os.path.exists(IMAGE_DIR)}\")\n",
        "\n",
        "if os.path.exists(IMAGE_DIR):\n",
        "    all_files = os.listdir(IMAGE_DIR)\n",
        "    image_files = [f for f in all_files if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    print(f\"Total files in directory: {len(all_files)}\")\n",
        "    print(f\"Image files found: {len(image_files)}\")\n",
        "    if image_files:\n",
        "        print(f\"Sample filenames: {image_files[:3]}\")\n",
        "else:\n",
        "    print(\" ERROR: Image directory does not exist!\")\n",
        "    print(\"Please check the IMAGE_DIR path\")\n",
        "\n",
        "print(f\"\\nSample expected filenames from JSON:\")\n",
        "sample_ids = list(id_to_filename.keys())[:3]\n",
        "for img_id in sample_ids:\n",
        "    expected_file = id_to_filename[img_id]\n",
        "    full_path = os.path.join(IMAGE_DIR, expected_file)\n",
        "    exists = os.path.exists(full_path)\n",
        "    print(f\"  {expected_file} - {' Found' if exists else ' Not found'}\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Load InceptionV3 pre-trained model\n",
        "print(\"\\nLoading InceptionV3 model (pre-trained on ImageNet)...\")\n",
        "inception = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
        "print(f\" Model loaded. Output shape: {inception.output.shape}\")\n",
        "\n",
        "def extract_image_features(image_path):\n",
        "\n",
        "    try:\n",
        "        img = load_img(image_path, target_size=IMG_SIZE)\n",
        "        img = img_to_array(img)\n",
        "        img = img / 255.0  # Normalize to [0, 1]\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = tf.keras.applications.inception_v3.preprocess_input(img * 255.0)\n",
        "        features = inception.predict(img, verbose=0)\n",
        "        return features[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Extract features for all images\n",
        "print(\"\\nExtracting image features...\")\n",
        "print(f\"Processing {NUM_IMAGES if NUM_IMAGES else 'all'} images...\")\n",
        "\n",
        "# Initialize image_ids from the JSON data\n",
        "image_ids = list(id_to_filename.keys())\n",
        "\n",
        "# Get list of actual image files in directory\n",
        "actual_image_files = set(os.listdir(IMAGE_DIR))\n",
        "print(f\"Actual images in folder: {len(actual_image_files)}\")\n",
        "\n",
        "# Filter available images that exist in both JSON and folder\n",
        "available_images = []\n",
        "for img_id in image_ids:\n",
        "    filename = id_to_filename[img_id]\n",
        "    if filename in actual_image_files:\n",
        "        available_images.append(img_id)\n",
        "\n",
        "print(f\"Images matching JSON annotations: {len(available_images)}\")\n",
        "\n",
        "# Limit to NUM_IMAGES if specified\n",
        "if NUM_IMAGES:\n",
        "    available_images = available_images[:NUM_IMAGES]\n",
        "    print(f\"Limited to: {NUM_IMAGES} images for {DATASET_SIZE} dataset\")\n",
        "\n",
        "image_features = {}\n",
        "\n",
        "# Batch processing for efficiency\n",
        "print(\"\\n Starting feature extraction (this may take a few minutes)...\")\n",
        "for img_id in tqdm(available_images, desc=\"Extracting features\"):\n",
        "    filename = id_to_filename[img_id]\n",
        "    img_path = os.path.join(IMAGE_DIR, filename)\n",
        "\n",
        "    features = extract_image_features(img_path)\n",
        "    if features is not None:\n",
        "        image_features[img_id] = features\n",
        "\n",
        "# Update image_ids to only include processed images\n",
        "image_ids = list(image_features.keys())\n",
        "print(f\"Successfully extracted features: {len(image_features)} images\")\n",
        "\n",
        "print(f\" Features extracted for {len(image_features)} images\")\n",
        "\n",
        "if len(image_features) == 0:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\" ERROR: No images were processed!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "# Save features to Google Drive\n",
        "feature_save_path = f'/content/drive/MyDrive/image_features_{DATASET_SIZE}.npy'\n",
        "np.save(feature_save_path, image_features)\n",
        "print(f\" Features saved to '{feature_save_path}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqbs7Wj8XtQv",
        "outputId": "52556a76-e28b-4296-8a6f-9dbf2197957b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded saved features!\n",
            "Number of images: 1000\n",
            "Feature shape: (2048,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "FEATURE_PATH = \"/content/drive/MyDrive/image_features_medium.npy\"\n",
        "image_features = np.load(FEATURE_PATH, allow_pickle=True).item()\n",
        "\n",
        "print(\"Loaded saved features!\")\n",
        "print(\"Number of images:\", len(image_features))\n",
        "print(\"Feature shape:\", list(image_features.values())[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebeMjaXXXWEA"
      },
      "source": [
        "**Step 3 — Preparing Captions for Training**\n",
        "\n",
        "This step converts every caption into many small input–output pairs so the model can learn to predict the next word. Each caption is cleaned, tokenized, padded, and matched with its image feature vector. For every partial caption, the model is taught which word should come next, allowing it to learn sentence structure and how words relate to the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAlEDG7uayqm",
        "outputId": "32d77a5b-82b1-4996-910f-5c9366d2aad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[STEP 3] PREPARING CAPTIONS FOR TRAINING\n",
            "--------------------------------------------------------------------------------\n",
            "Creating training sequences...\n",
            "This creates input-output pairs for teaching the model\n",
            "\n",
            "Example caption: <start> a black honda motorcycle parked in front of a garage <end>\n",
            "Input-Output pairs:\n",
            "  Input: <start> → Output: a\n",
            "  Input: <start> a → Output: black\n",
            "  Input: <start> a black → Output: honda\n",
            "  Input: <start> a black honda → Output: motorcycle\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 3: PREPARING CAPTIONS FOR TRAINING\n",
        "# ============================================================================\n",
        "print(\"\\n[STEP 3] PREPARING CAPTIONS FOR TRAINING\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def create_sequences(image_ids, image_features, captions_dict, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Create input-output pairs for training\n",
        "    For caption \"A cat is sitting\":\n",
        "      Input: <start>, Output: A\n",
        "      Input: <start> A, Output: cat\n",
        "      Input: <start> A cat, Output: is\n",
        "      etc.\n",
        "    \"\"\"\n",
        "    X_img, X_seq, y_word = [], [], []\n",
        "\n",
        "    for img_id in image_ids:\n",
        "        if img_id not in image_features:\n",
        "            continue\n",
        "\n",
        "        feature = image_features[img_id]\n",
        "        captions = captions_dict[img_id]\n",
        "\n",
        "        for caption in captions:\n",
        "            caption = preprocess_caption(caption)\n",
        "            seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "\n",
        "            # Create input-output pairs\n",
        "            for i in range(1, len(seq)):\n",
        "                in_seq = seq[:i]\n",
        "                out_word = seq[i]\n",
        "\n",
        "                # Pad input sequence\n",
        "                in_seq = pad_sequences([in_seq], maxlen=max_length, padding='post')[0]\n",
        "\n",
        "                # One-hot encode output\n",
        "                out_word = to_categorical([out_word], num_classes=vocab_size)[0]\n",
        "\n",
        "                X_img.append(feature)\n",
        "                X_seq.append(in_seq)\n",
        "                y_word.append(out_word)\n",
        "\n",
        "    return np.array(X_img), np.array(X_seq), np.array(y_word)\n",
        "\n",
        "print(\"Creating training sequences...\")\n",
        "print(\"This creates input-output pairs for teaching the model\")\n",
        "\n",
        "# Example of input-output pairs\n",
        "sample_caption = all_captions[0]\n",
        "sample_tokens = sample_caption.split()\n",
        "print(f\"\\nExample caption: {sample_caption}\")\n",
        "print(\"Input-Output pairs:\")\n",
        "for i in range(1, min(5, len(sample_tokens))):\n",
        "    print(f\"  Input: {' '.join(sample_tokens[:i])} → Output: {sample_tokens[i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixWtLPRvXhDf"
      },
      "source": [
        "***Step 4 — Building the Model***\n",
        "\n",
        "In this step, I create the full image-captioning neural network by combining an image encoder, a caption decoder, and an attention mechanism. The encoder transforms image features into a meaningful vector, the decoder interprets the partial caption, and attention helps the model focus on important parts when generating each word. The final layer predicts the next word in the caption. The model is then compiled with Adam optimizer and label smoothing for stable learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "GiofTdkc5O-a",
        "outputId": "710eedf5-700b-488c-a3a7-67711d006194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[STEP 4] BUILDING THE MODEL\n",
            "--------------------------------------------------------------------------------\n",
            "Creating model architecture...\n",
            "\n",
            " Model architecture:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"image_captioning_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"image_captioning_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ caption_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ image_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ caption_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m1,024,000\u001b[0m │ caption_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ caption_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ caption_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ image_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,049,088\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ caption_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,574,912\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ image_encoder[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ caption_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_merge     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ attention_merge[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ decoder_dense[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4000\u001b[0m)      │  \u001b[38;5;34m2,052,000\u001b[0m │ batch_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ caption_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ image_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ caption_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024,000</span> │ caption_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ caption_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ caption_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ image_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ caption_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ image_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ caption_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ attention_merge     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ attention_merge[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4000</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,052,000</span> │ batch_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,968,800\u001b[0m (22.77 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,968,800</span> (22.77 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,965,728\u001b[0m (22.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,965,728</span> (22.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Compiling model with Adam optimizer and Label Smoothing...\n",
            " Model compiled successfully\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 4: BUILDING THE MODEL\n",
        "# ============================================================================\n",
        "print(\"\\n[STEP 4] BUILDING THE MODEL\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def build_attention_model(vocab_size, max_length, embedding_dim, lstm_units):\n",
        "    \"\"\"\n",
        "    Build Encoder-Decoder model with Attention mechanism\n",
        "    IMPROVED with better regularization and architecture\n",
        "\n",
        "    Architecture:\n",
        "    1. Encoder: Process image features through Dense layers\n",
        "    2. Decoder: Process caption sequences through Embedding + LSTM\n",
        "    3. Attention: Focus on relevant image parts for each word\n",
        "    4. Output: Predict next word\n",
        "    \"\"\"\n",
        "\n",
        "    # ===== ENCODER: Image Feature Processing =====\n",
        "    input_image = Input(shape=(2048,), name='image_input')\n",
        "    image_enc = Dropout(0.5)(input_image)\n",
        "    image_enc = Dense(lstm_units, activation='relu', name='image_encoder')(image_enc)  # Changed embedding_dim to lstm_units\n",
        "    image_enc = keras.layers.BatchNormalization()(image_enc)  # Add batch normalization\n",
        "\n",
        "    # ===== DECODER: Caption Sequence Processing =====\n",
        "    input_caption = Input(shape=(max_length,), name='caption_input')\n",
        "    caption_enc = Embedding(vocab_size, embedding_dim, mask_zero=True, name='caption_embedding')(input_caption)\n",
        "    caption_enc = Dropout(0.5)(caption_enc)\n",
        "    # Add recurrent dropout to prevent overfitting\n",
        "    caption_enc = LSTM(lstm_units, return_sequences=False, recurrent_dropout=0.2, name='caption_lstm')(caption_enc)\n",
        "    caption_enc = keras.layers.BatchNormalization()(caption_enc)  # Add batch normalization\n",
        "\n",
        "    # ===== ATTENTION MECHANISM =====\n",
        "    # Combine image and caption features\n",
        "    decoder = Add(name='attention_merge')([image_enc, caption_enc])\n",
        "    decoder = Dense(lstm_units, activation='relu', name='decoder_dense')(decoder)\n",
        "    decoder = Dropout(0.5)(decoder)\n",
        "    decoder = keras.layers.BatchNormalization()(decoder)  # Add batch normalization\n",
        "\n",
        "    # ===== OUTPUT LAYER =====\n",
        "    output = Dense(vocab_size, activation='softmax', name='output')(decoder)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=[input_image, input_caption], outputs=output, name='image_captioning_model')\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"Creating model architecture...\")\n",
        "model = build_attention_model(vocab_size, max_length, EMBEDDING_DIM, LSTM_UNITS)\n",
        "\n",
        "print(\"\\n Model architecture:\")\n",
        "model.summary()\n",
        "\n",
        "# Compile model with Label Smoothing to prevent overconfidence\n",
        "print(\"\\nCompiling model with Adam optimizer and Label Smoothing...\")\n",
        "model.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),  # Reduces overconfidence\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(\" Model compiled successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGtispF6aKjn"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLic4xeZX6iS"
      },
      "source": [
        "***Step 5 — Training the Model***\n",
        "\n",
        "In this step, I prepare the final dataset and train the image-captioning model. The image IDs are split into training and validation sets, and each image-caption pair is converted into the sequence format required by the model. The model is then trained using both image features and caption sequences, while callbacks like checkpointing, early stopping, and learning-rate reduction help stabilize and improve training. After training finishes, the best model is saved and the training history is plotted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O6vHq8Z65PBe",
        "outputId": "e78946ac-e377-45d3-8e56-86c72731810f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[STEP 5] TRAINING THE MODEL\n",
            "--------------------------------------------------------------------------------\n",
            "Training images: 800\n",
            "Validation images: 200\n",
            "\n",
            "Preparing training data...\n",
            " Training samples: 46051\n",
            "Preparing validation data...\n",
            " Validation samples: 11465\n",
            "\n",
            "Starting training...\n",
            "Epochs: 20\n",
            "Batch size: 16\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.2044 - loss: 6.1465\n",
            "Epoch 1: val_loss improved from inf to 4.68017, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 91ms/step - accuracy: 0.2045 - loss: 6.1462 - val_accuracy: 0.3212 - val_loss: 4.6802 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.3209 - loss: 4.5719\n",
            "Epoch 2: val_loss improved from 4.68017 to 4.42351, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 91ms/step - accuracy: 0.3209 - loss: 4.5719 - val_accuracy: 0.3473 - val_loss: 4.4235 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3489 - loss: 4.2592\n",
            "Epoch 3: val_loss improved from 4.42351 to 4.33841, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 91ms/step - accuracy: 0.3489 - loss: 4.2592 - val_accuracy: 0.3559 - val_loss: 4.3384 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3687 - loss: 4.0590\n",
            "Epoch 4: val_loss improved from 4.33841 to 4.30355, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 92ms/step - accuracy: 0.3687 - loss: 4.0590 - val_accuracy: 0.3633 - val_loss: 4.3035 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3840 - loss: 3.9286\n",
            "Epoch 5: val_loss improved from 4.30355 to 4.28951, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 91ms/step - accuracy: 0.3840 - loss: 3.9286 - val_accuracy: 0.3632 - val_loss: 4.2895 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3931 - loss: 3.8467\n",
            "Epoch 6: val_loss improved from 4.28951 to 4.27200, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 91ms/step - accuracy: 0.3931 - loss: 3.8467 - val_accuracy: 0.3678 - val_loss: 4.2720 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4023 - loss: 3.7713\n",
            "Epoch 7: val_loss did not improve from 4.27200\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 91ms/step - accuracy: 0.4023 - loss: 3.7713 - val_accuracy: 0.3678 - val_loss: 4.2790 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4112 - loss: 3.7013\n",
            "Epoch 8: val_loss improved from 4.27200 to 4.26480, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 92ms/step - accuracy: 0.4112 - loss: 3.7013 - val_accuracy: 0.3734 - val_loss: 4.2648 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.4249 - loss: 3.6311\n",
            "Epoch 9: val_loss improved from 4.26480 to 4.26254, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 92ms/step - accuracy: 0.4249 - loss: 3.6311 - val_accuracy: 0.3731 - val_loss: 4.2625 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.4259 - loss: 3.5995\n",
            "Epoch 10: val_loss improved from 4.26254 to 4.26198, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 91ms/step - accuracy: 0.4259 - loss: 3.5995 - val_accuracy: 0.3762 - val_loss: 4.2620 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.4366 - loss: 3.5385\n",
            "Epoch 11: val_loss did not improve from 4.26198\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 91ms/step - accuracy: 0.4366 - loss: 3.5385 - val_accuracy: 0.3793 - val_loss: 4.2795 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4382 - loss: 3.5252\n",
            "Epoch 12: val_loss did not improve from 4.26198\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 92ms/step - accuracy: 0.4382 - loss: 3.5252 - val_accuracy: 0.3750 - val_loss: 4.2733 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.4477 - loss: 3.4689\n",
            "Epoch 13: val_loss did not improve from 4.26198\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 93ms/step - accuracy: 0.4477 - loss: 3.4689 - val_accuracy: 0.3744 - val_loss: 4.3221 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.4618 - loss: 3.3910\n",
            "Epoch 14: val_loss did not improve from 4.26198\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 91ms/step - accuracy: 0.4618 - loss: 3.3910 - val_accuracy: 0.3820 - val_loss: 4.2754 - learning_rate: 2.5000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4689 - loss: 3.3391\n",
            "Epoch 15: val_loss did not improve from 4.26198\n",
            "\u001b[1m2879/2879\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 91ms/step - accuracy: 0.4689 - loss: 3.3391 - val_accuracy: 0.3819 - val_loss: 4.2877 - learning_rate: 2.5000e-04\n",
            "Epoch 15: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training completed!\n",
            " Model saved to 'final_model.h5'\n",
            " Training plots saved to 'training_history.png'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 5: TRAINING THE MODEL\n",
        "# ============================================================================\n",
        "print(\"\\n[STEP 5] TRAINING THE MODEL\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "import numpy as np  # Ensure numpy is imported\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "# Fallback for DATASET_SIZE if not defined (e.g., after kernel restart)\n",
        "if 'DATASET_SIZE' not in locals():\n",
        "    DATASET_SIZE = 'large' # Defaulting to 'large' if not set globally\n",
        "    print(f\"Warning: DATASET_SIZE not found, defaulting to '{DATASET_SIZE}'. Please run the CONFIGURATION cell first.\")\n",
        "\n",
        "# Fallback for CAPTION_FILE if not defined (e.g., after kernel restart)\n",
        "if 'CAPTION_FILE' not in locals():\n",
        "    # This path should match your configuration cell's CAPTION_FILE\n",
        "    CAPTION_FILE = \"/content/drive/MyDrive/Colab Notebooks/Major project/Annotations/captions_val2017.json\"\n",
        "    print(f\"Warning: CAPTION_FILE not found, defaulting to '{CAPTION_FILE}'. Please run the CONFIGURATION cell first.\")\n",
        "\n",
        "# Define create_sequences function (moved here for robustness against kernel restarts)\n",
        "def create_sequences(image_ids, image_features, captions_dict, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Create input-output pairs for training\n",
        "    For caption \"A cat is sitting\":\n",
        "      Input: <start>, Output: A\n",
        "      Input: <start> A, Output: cat\n",
        "      Input: <start> A cat, Output: is\n",
        "      etc.\n",
        "    \"\"\"\n",
        "    X_img, X_seq, y_word = [], [], []\n",
        "\n",
        "    for img_id in image_ids:\n",
        "        if img_id not in image_features:\n",
        "            continue\n",
        "\n",
        "        feature = image_features[img_id]\n",
        "        captions = captions_dict[img_id]\n",
        "\n",
        "        for caption in captions:\n",
        "            # Ensure preprocess_caption is available, or redefine if needed\n",
        "            if 'preprocess_caption' in globals():\n",
        "                processed_caption = preprocess_caption(caption)\n",
        "            else:\n",
        "                # Fallback definition if kernel state is lost\n",
        "                def _local_preprocess_caption(caption):\n",
        "                    caption = caption.lower()\n",
        "                    caption = ''.join([c for c in caption if c.isalnum() or c.isspace()])\n",
        "                    caption = '<start> ' + ' '.join(caption.split()) + ' <end>'\n",
        "                    return _local_preprocess_caption(caption)\n",
        "                processed_caption = _local_preprocess_caption(caption)\n",
        "\n",
        "            seq = tokenizer.texts_to_sequences([processed_caption])[0]\n",
        "\n",
        "            # Create input-output pairs\n",
        "            for i in range(1, len(seq)):\n",
        "                in_seq = seq[:i]\n",
        "                out_word = seq[i]\n",
        "\n",
        "                # Pad input sequence\n",
        "                in_seq = pad_sequences([in_seq], maxlen=max_length, padding='post')[0]\n",
        "\n",
        "                # One-hot encode output\n",
        "                out_word = to_categorical([out_word], num_classes=vocab_size)[0]\n",
        "\n",
        "                X_img.append(feature)\n",
        "                X_seq.append(in_seq)\n",
        "                y_word.append(out_word)\n",
        "\n",
        "    return np.array(X_img), np.array(X_seq), np.array(y_word)\n",
        "\n",
        "# Load MS COCO captions and image mappings if not already in memory\n",
        "if 'image_to_captions' not in locals() or 'id_to_filename' not in locals():\n",
        "    print(\"Reloading MS COCO captions and image mappings...\")\n",
        "    with open(CAPTION_FILE, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    image_to_captions = defaultdict(list)\n",
        "    for annotation in coco_data['annotations']:\n",
        "        image_id = annotation['image_id']\n",
        "        caption = annotation['caption']\n",
        "        image_to_captions[image_id].append(caption)\n",
        "\n",
        "    id_to_filename = {}\n",
        "    for image in coco_data['images']:\n",
        "        id_to_filename[image['id']] = image['file_name']\n",
        "    print(\"Captions and image mappings reloaded.\")\n",
        "\n",
        "# Ensure image_ids is defined from the loaded features\n",
        "image_ids = list(image_features.keys())\n",
        "\n",
        "# Split data: 80% training, 20% validation\n",
        "split_idx = int(0.8 * len(image_ids))\n",
        "train_ids = [img_id for img_id in image_ids[:split_idx] if img_id in image_features]\n",
        "val_ids = [img_id for img_id in image_ids[split_idx:] if img_id in image_features]\n",
        "\n",
        "print(f\"Training images: {len(train_ids)}\")\n",
        "print(f\"Validation images: {len(val_ids)}\")\n",
        "\n",
        "# Prepare training data\n",
        "print(\"\\nPreparing training data...\")\n",
        "X_train_img, X_train_seq, y_train = create_sequences(\n",
        "    train_ids, image_features, image_to_captions, tokenizer, max_length\n",
        ")\n",
        "print(f\" Training samples: {len(X_train_img)}\")\n",
        "\n",
        "# Prepare validation data\n",
        "print(\"Preparing validation data...\")\n",
        "X_val_img, X_val_seq, y_val = create_sequences(\n",
        "    val_ids, image_features, image_to_captions, tokenizer, max_length\n",
        ")\n",
        "print(f\" Validation samples: {len(X_val_img)}\")\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        'best_model.h5',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        verbose=1,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train model\n",
        "print(\"\\nStarting training...\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_img, X_train_seq],\n",
        "    y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=([X_val_img, X_val_seq], y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n Training completed!\")\n",
        "model.save('final_model.h5')\n",
        "print(\" Model saved to 'final_model.h5'\")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png')\n",
        "print(\" Training plots saved to 'training_history.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Insights**\n",
        "\n",
        "During Step 5, the model was trained using 800 training images and 200 validation images, which expanded into 46,051 training samples and 11,465 validation samples after caption–token preparation. The model was trained for a maximum of 20 epochs with a batch size of 16, and the training process showed steady improvement in both accuracy and loss during the early phases. The first epoch achieved an accuracy of 0.2044 with a validation loss of 4.68, and the model continued improving until Epoch 10, where it reached a validation loss of 4.2619, the best point of the entire training run. After Epoch 13, learning rate reduction was triggered due to plateauing, and by Epoch 15, early stopping halted further training because the model was no longer improving. The best model weights (from Epoch 10) were restored automatically. Training concluded successfully, and the final model was saved as final_model.h5, along with generated training-loss and accuracy plots stored in training_history.png."
      ],
      "metadata": {
        "id": "S0inaYMB0Qvd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZnF24fDk_67"
      },
      "outputs": [],
      "source": [
        "!cp best_model.h5 \"/content/drive/MyDrive/Colab Notebooks/Major project/Model/best_model.h5\"\n",
        "!cp final_model.h5 \"/content/drive/MyDrive/Colab Notebooks/Major project/Model/final_model.h5\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4szYlgpAYaC2"
      },
      "source": [
        "***Step 6 — Model Evaluation***\n",
        "\n",
        "In this step, I evaluate the trained captioning model using BLEU scores, which measure how close the generated captions are to the true captions. Beam search is used during prediction to improve caption quality by exploring multiple possible word sequences. BLEU-1 to BLEU-4 scores are computed on a subset of validation images, and sample predictions are displayed to compare the generated captions with their actual ground-truth captions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AFnB1Ne5PFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c3691d-0191-40a1-d1c0-8e17a5085e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[STEP 6] MODEL EVALUATION\n",
            "--------------------------------------------------------------------------------\n",
            "Calculating BLEU scores...\n",
            "Generating captions for evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [04:09<00:00,  2.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ BLEU Scores:\n",
            "  BLEU-1: 0.5295\n",
            "  BLEU-2: 0.3431\n",
            "  BLEU-3: 0.2278\n",
            "  BLEU-4: 0.1593\n",
            "\n",
            "================================================================================\n",
            "SAMPLE PREDICTIONS\n",
            "================================================================================\n",
            "\n",
            "Image 1:\n",
            "Generated: a brown dog is standing in the grass\n",
            "Actual captions:\n",
            "  1. A dog that is wearing a dog collar smiling\n",
            "  2. A black and brown dog is wearing a heavy metal collar.\n",
            "  3. A medium sized dog is standing with some people.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Image 2:\n",
            "Generated: there are many people sitting on the ground\n",
            "Actual captions:\n",
            "  1. An umbrella and rain boots sitting on a rug in a corner. \n",
            "  2. An umbrella and rain boots in a corner \n",
            "  3. A view of a pair of boots sitting in a corner, with an umbrella.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Image 3:\n",
            "Generated: a person holding a umbrella with umbrella\n",
            "Actual captions:\n",
            "  1. People are walking in the rain holding umbrellas.\n",
            "  2. Several different opened umbrellas all located near each other.\n",
            "  3. Several plaid and red umbrellas opened on a dreary day.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Image 4:\n",
            "Generated: a group of people standing next to each other\n",
            "Actual captions:\n",
            "  1. A woman sitting at a table in front of a pile of luggage\n",
            "  2. A huge pile of luggage sits by the door.\n",
            "  3. A pile of luggage in a room with two women nearby.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Image 5:\n",
            "Generated: a group of people standing next to a sidewalk\n",
            "Actual captions:\n",
            "  1. a man is walking his dog through the city\n",
            "  2. A man walks his dog down the sidewalk.\n",
            "  3. A man is walking a dog on a sidewalk.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# STEP 6: MODEL EVALUATION\n",
        "# ============================================================================\n",
        "print(\"\\n[STEP 6] MODEL EVALUATION\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "def generate_caption(model, tokenizer, image_features, max_length, beam_width=3):\n",
        "    \"\"\"\n",
        "    Generate caption for an image using BEAM SEARCH\n",
        "    Beam search explores multiple hypotheses to avoid repetitive/generic captions\n",
        "\n",
        "    Args:\n",
        "        beam_width: Number of best candidates to keep at each step (higher = more diverse)\n",
        "    \"\"\"\n",
        "    # Start with initial sequence\n",
        "    start_token = tokenizer.texts_to_sequences(['<start>'])[0][0]\n",
        "\n",
        "    # Initialize beam: [(sequence, cumulative_log_prob)]\n",
        "    sequences = [([start_token], 0.0)]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        all_candidates = []\n",
        "\n",
        "        for seq, score in sequences:\n",
        "            # Stop if sequence ends\n",
        "            if seq[-1] == tokenizer.texts_to_sequences(['<end>'])[0][0]:\n",
        "                all_candidates.append((seq, score))\n",
        "                continue\n",
        "\n",
        "            # Prepare input\n",
        "            padded = pad_sequences([seq], maxlen=max_length, padding='post')\n",
        "\n",
        "            # Predict next word probabilities\n",
        "            preds = model.predict([image_features, padded], verbose=0)[0]\n",
        "\n",
        "            # Get top beam_width predictions\n",
        "            top_indices = np.argsort(preds)[-beam_width:]\n",
        "\n",
        "            # Add to candidates with updated scores\n",
        "            for idx in top_indices:\n",
        "                candidate = (seq + [idx], score - np.log(preds[idx] + 1e-10))\n",
        "                all_candidates.append(candidate)\n",
        "\n",
        "        # Select top beam_width sequences\n",
        "        ordered = sorted(all_candidates, key=lambda x: x[1])\n",
        "        sequences = ordered[:beam_width]\n",
        "\n",
        "    # Return best sequence\n",
        "    best_seq = sequences[0][0]\n",
        "\n",
        "    # Convert to words\n",
        "    caption = []\n",
        "    for idx in best_seq:\n",
        "        for word, word_idx in tokenizer.word_index.items():\n",
        "            if word_idx == idx:\n",
        "                if word not in ['<start>', '<end>', '<unk>']:\n",
        "                    caption.append(word)\n",
        "                break\n",
        "\n",
        "    return ' '.join(caption)\n",
        "\n",
        "# Calculate BLEU scores\n",
        "def calculate_bleu_scores(model, image_ids, image_features, captions_dict, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Calculate BLEU scores for model evaluation\n",
        "    BLEU measures how similar generated captions are to reference captions\n",
        "    \"\"\"\n",
        "    actual_captions = []\n",
        "    predicted_captions = []\n",
        "\n",
        "    print(\"Generating captions for evaluation...\")\n",
        "    for img_id in tqdm(image_ids[:100]):  # Evaluate on 100 images\n",
        "        if img_id not in image_features:\n",
        "            continue\n",
        "\n",
        "        # Get actual captions\n",
        "        references = [preprocess_caption(cap).replace('<start>', '').replace('<end>', '').strip().split()\n",
        "                      for cap in captions_dict[img_id]]\n",
        "        actual_captions.append(references)\n",
        "\n",
        "        # Generate predicted caption\n",
        "        features = np.expand_dims(image_features[img_id], axis=0)\n",
        "        predicted = generate_caption(model, tokenizer, features, max_length)\n",
        "        predicted_captions.append(predicted.split())\n",
        "\n",
        "    # Calculate BLEU scores\n",
        "    bleu1 = corpus_bleu(actual_captions, predicted_captions, weights=(1.0, 0, 0, 0))\n",
        "    bleu2 = corpus_bleu(actual_captions, predicted_captions, weights=(0.5, 0.5, 0, 0))\n",
        "    bleu3 = corpus_bleu(actual_captions, predicted_captions, weights=(0.33, 0.33, 0.33, 0))\n",
        "    bleu4 = corpus_bleu(actual_captions, predicted_captions, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "    return bleu1, bleu2, bleu3, bleu4\n",
        "\n",
        "print(\"Calculating BLEU scores...\")\n",
        "bleu1, bleu2, bleu3, bleu4 = calculate_bleu_scores(\n",
        "    model, val_ids, image_features, image_to_captions, tokenizer, max_length\n",
        ")\n",
        "\n",
        "print(\"\\n✓ BLEU Scores:\")\n",
        "print(f\"  BLEU-1: {bleu1:.4f}\")\n",
        "print(f\"  BLEU-2: {bleu2:.4f}\")\n",
        "print(f\"  BLEU-3: {bleu3:.4f}\")\n",
        "print(f\"  BLEU-4: {bleu4:.4f}\")\n",
        "\n",
        "# Test on sample images\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SAMPLE PREDICTIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, img_id in enumerate(val_ids[:5]):\n",
        "    if img_id not in image_features:\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nImage {i+1}:\")\n",
        "    features = np.expand_dims(image_features[img_id], axis=0)\n",
        "    predicted = generate_caption(model, tokenizer, features, max_length)\n",
        "\n",
        "    print(f\"Generated: {predicted}\")\n",
        "    print(f\"Actual captions:\")\n",
        "    for j, cap in enumerate(image_to_captions[img_id][:3], 1):\n",
        "        print(f\"  {j}. {cap}\")\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Insights**\n",
        "\n",
        "In Step 6, the model’s performance was evaluated using BLEU metrics and sample caption predictions. The BLEU evaluation showed moderate linguistic alignment with reference captions, achieving BLEU-1 of 0.5295, gradually tapering to BLEU-4 of 0.1593, which is typical for captioning models trained on limited data. Sample predictions reflect that the model captures general scene structure but often produces broad or mismatched descriptions due to dataset size and training constraints. For example, scenes involving dogs, umbrellas, or luggage were recognized only at a coarse level, and several outputs remained generic. Overall, the evaluation indicates that the model learned basic visual-semantic patterns but requires more data or longer training to produce more detailed and contextually accurate captions."
      ],
      "metadata": {
        "id": "uE5Buk58cbw_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQxiWM4o5PIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f104387-b813-4f66-fdc0-c6c0cbfa1998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/Colab Notebooks/Major project/Model/caption_model.keras\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the directory path where you want to save the model\n",
        "model_save_dir = '/content/drive/MyDrive/Colab Notebooks/Major project/Model'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(model_save_dir):\n",
        "    os.makedirs(model_save_dir)\n",
        "    print(f\"Created directory: {model_save_dir}\")\n",
        "\n",
        "# Define the full path for saving the model with a .keras extension\n",
        "model_save_path = os.path.join(model_save_dir, 'caption_model.keras')\n",
        "\n",
        "# Save the model\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to: {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP1K-W8Z5PL0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Major project/Model/tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15jyPbPPkPtZ"
      },
      "outputs": [],
      "source": [
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/Major project/Model/image_features.npy\", image_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIlxkYlrkTAD"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model_caption = tf.keras.models.load_model(\n",
        "    \"/content/drive/MyDrive/Colab Notebooks/Major project/Model/caption_model.keras\"\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Major project/Model/tokenizer.pkl\", \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}